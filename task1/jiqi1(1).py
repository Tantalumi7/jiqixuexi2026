# =============================================================================
# NEU Plant Seedling Classification 2025 - Traditional ML Pipeline (Final Fixed)
# Strategy: SIFT-BoVW + HOG + LBP + HuMoments + ColorStats + Ensemble
# =============================================================================

import os
import cv2
import numpy as np
import pandas as pd
from sklearn.cluster import MiniBatchKMeans
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from sklearn.model_selection import cross_val_score
from skimage.feature import local_binary_pattern, hog
from xgboost import XGBClassifier
import warnings

warnings.filterwarnings('ignore')

# ===========================
# 1. æ™ºèƒ½è·¯å¾„é…ç½® (è‡ªåŠ¨æ£€æµ‹å¤§å°å†™)
# ===========================
BASE_PATH = '/kaggle/input/neu-plant-seedling-classification-2025/dataset-for-task1'

def find_folder(base, name_options):
    """åœ¨ base ç›®å½•ä¸‹å¯»æ‰¾ name_options ä¸­çš„ä»»æ„ä¸€ä¸ªæ–‡ä»¶å¤¹"""
    if not os.path.exists(base):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ ¹ç›®å½•: {base}ï¼Œè¯·æ£€æŸ¥æ¯”èµ›æ•°æ®é›†æ˜¯å¦å·²æ·»åŠ ã€‚")
    
    available = os.listdir(base)
    for opt in name_options:
        if opt in available:
            return os.path.join(base, opt)
    raise FileNotFoundError(f"åœ¨ {base} ä¸‹æ‰¾ä¸åˆ° {name_options} ä¸­çš„ä»»ä½•æ–‡ä»¶å¤¹ã€‚ç°æœ‰å†…å®¹: {available}")

# è‡ªåŠ¨å¯»æ‰¾ train/Train å’Œ test/Test
print("æ­£åœ¨æ£€æµ‹æ•°æ®è·¯å¾„...")
TRAIN_DIR = find_folder(BASE_PATH, ['train', 'Train'])
TEST_DIR = find_folder(BASE_PATH, ['test', 'Test'])

print(f"âœ… è®­ç»ƒé›†è·¯å¾„: {TRAIN_DIR}")
print(f"âœ… æµ‹è¯•é›†è·¯å¾„: {TEST_DIR}")

# å‚æ•°è®¾ç½®
IMG_SIZE = 300           
VOCAB_SIZE = 400         # è§†è§‰è¯å…¸å¤§å°
SEED = 2025

# ===========================
# 2. å›¾åƒé¢„å¤„ç† (å»èƒŒæ™¯)
# ===========================
def preprocess_image(img):
    """è½¬æ¢ä¸ºHSV -> ç»¿è‰²æ©è†œ -> å½¢æ€å­¦å»å™ª -> ä¿ç•™æœ€å¤§è½®å»“"""
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    
    # ç»¿è‰²èŒƒå›´ (å…³é”®å‚æ•°)
    lower_green = np.array([25, 35, 35])
    upper_green = np.array([86, 255, 255])
    mask = cv2.inRange(hsv, lower_green, upper_green)
    
    # å½¢æ€å­¦æ“ä½œ
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)
    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=2)
    
    # åªä¿ç•™æœ€å¤§è½®å»“
    cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if len(cnts) > 0:
        c = max(cnts, key=cv2.contourArea)
        mask_clean = np.zeros_like(mask)
        cv2.drawContours(mask_clean, [c], -1, 255, -1)
        mask = mask_clean
        
    result = cv2.bitwise_and(img, img, mask=mask)
    return result, mask

# ===========================
# 3. ç‰¹å¾æå– (æ ¸å¿ƒé€»è¾‘)
# ===========================
# å…¼å®¹ä¸åŒç‰ˆæœ¬çš„ OpenCV SIFT
try:
    sift = cv2.SIFT_create()
except:
    try:
        sift = cv2.xfeatures2d.SIFT_create()
    except:
        print("è­¦å‘Š: æ— æ³•åˆå§‹åŒ– SIFTï¼Œè¯·æ£€æŸ¥ opencv-python å’Œ opencv-contrib-python ç‰ˆæœ¬")

def extract_features(img, kmeans_model):
    """æå– SIFT(BoVW) + HOG + LBP + Hu + Color"""
    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))
    clean_img, mask = preprocess_image(img)
    gray = cv2.cvtColor(clean_img, cv2.COLOR_BGR2GRAY)
    
    features = []
    
    # 1. SIFT BoVW
    kp, des = sift.detectAndCompute(gray, mask)
    vocab_hist = np.zeros(VOCAB_SIZE)
    if des is not None and len(des) > 0:
        words = kmeans_model.predict(des.astype(np.float64))
        for w in words: vocab_hist[w] += 1
    if vocab_hist.sum() > 0: vocab_hist /= vocab_hist.sum()
    features.extend(vocab_hist)
    
    # 2. HOG (Shape)
    try:
        fd_hog = hog(gray, orientations=9, pixels_per_cell=(16, 16),
                     cells_per_block=(2, 2), visualize=False)
        features.extend(fd_hog)
    except:
        features.extend([0]*1000) # å®¹é”™

    # 3. LBP (Texture)
    radius = 3
    n_points = 8 * radius
    lbp = local_binary_pattern(gray, n_points, radius, method="uniform")
    (hist_lbp, _) = np.histogram(lbp.ravel(), bins=np.arange(0, n_points + 3), range=(0, n_points + 2))
    hist_lbp = hist_lbp.astype("float")
    hist_lbp /= (hist_lbp.sum() + 1e-6)
    features.extend(hist_lbp)
    
    # 4. Hu Moments (Geometry)
    hu = cv2.HuMoments(cv2.moments(mask)).flatten()
    hu = -np.sign(hu) * np.log10(np.abs(hu) + 1e-10)
    features.extend(hu)
    
    # 5. Color Stats
    hsv_img = cv2.cvtColor(clean_img, cv2.COLOR_BGR2HSV)
    for i in range(3):
        pixels = hsv_img[:,:,i][mask > 0]
        if len(pixels) > 0: features.extend([pixels.mean(), pixels.std()])
        else: features.extend([0, 0])
            
    return np.array(features)

# ===========================
# 4. è®­ç»ƒæµç¨‹
# ===========================
def main():
    # --- Step 1: è¯»å–æ‰€æœ‰è®­ç»ƒå›¾ç‰‡ç”¨äºæ„å»ºè¯å…¸ ---
    print(">>> æ­£åœ¨æ‰«æè®­ç»ƒæ•°æ®...")
    train_paths = []
    train_labels = []

    for label in os.listdir(TRAIN_DIR):
        class_dir = os.path.join(TRAIN_DIR, label)
        if not os.path.isdir(class_dir): continue
        for f in os.listdir(class_dir):
            if f.lower().endswith(('.png', '.jpg', '.jpeg')):
                train_paths.append(os.path.join(class_dir, f))
                train_labels.append(label)
    
    print(f"æ‰¾åˆ° {len(train_paths)} å¼ è®­ç»ƒå›¾ç‰‡ã€‚")

    # --- Step 2: æ„å»º SIFT è¯å…¸ ---
    print(">>> æ­£åœ¨æ„å»º SIFT è¯å…¸ (KMeans)...")
    descriptors = []
    # é‡‡æ ·éƒ¨åˆ†å›¾ç‰‡åŠ é€Ÿ (å¦‚æœæƒ³æ›´å‡†ï¼Œå¯ä»¥å¢åŠ é‡‡æ ·æ•°)
    sample_paths = np.random.choice(train_paths, min(len(train_paths), 1000), replace=False)
    
    for path in sample_paths:
        img = cv2.imread(path)
        if img is None: continue
        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))
        _, mask = preprocess_image(img)
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        kp, des = sift.detectAndCompute(gray, mask)
        if des is not None: descriptors.append(des)
            
    all_des = np.vstack(descriptors)
    kmeans = MiniBatchKMeans(n_clusters=VOCAB_SIZE, batch_size=1000, random_state=SEED).fit(all_des)
    print("âœ… è¯å…¸æ„å»ºå®Œæˆã€‚")

    # --- Step 3: æå–è®­ç»ƒç‰¹å¾ ---
    print(">>> æ­£åœ¨æå–è®­ç»ƒé›†ç‰¹å¾ (è¿™éœ€è¦å‡ åˆ†é’Ÿ)...")
    X_train = []
    for i, path in enumerate(train_paths):
        img = cv2.imread(path)
        X_train.append(extract_features(img, kmeans))
        if i % 100 == 0: print(f"è¿›åº¦: {i}/{len(train_paths)}", end='\r')
    
    X_train = np.array(X_train)
    y_train = np.array(train_labels)
    
    # é¢„å¤„ç†
    le = LabelEncoder()
    y_enc = le.fit_transform(y_train)
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X_train)
    
    print(f"\nç‰¹å¾æå–å®Œæ¯•ã€‚ç»´åº¦: {X_train.shape}")

    # --- Step 4: è®­ç»ƒæ¨¡å‹ (Stacking) ---
    print(">>> æ­£åœ¨è®­ç»ƒé›†æˆæ¨¡å‹...")
    # SVM: ä½¿ç”¨ balanced æƒé‡è§£å†³ä¸å¹³è¡¡
    clf_svm = SVC(C=10, kernel='rbf', probability=True, class_weight='balanced', random_state=SEED)
    # RF
    clf_rf = RandomForestClassifier(n_estimators=300, class_weight='balanced', random_state=SEED, n_jobs=-1)
    # XGB
    clf_xgb = XGBClassifier(n_estimators=500, learning_rate=0.05, max_depth=6, eval_metric='mlogloss', random_state=SEED, n_jobs=-1)

    eclf = VotingClassifier(estimators=[('svm', clf_svm), ('rf', clf_rf), ('xgb', clf_xgb)], voting='soft')
    
    eclf.fit(X_scaled, y_enc)
    print("âœ… æ¨¡å‹è®­ç»ƒå®Œæ¯•ã€‚")

    # --- Step 5: é¢„æµ‹æµ‹è¯•é›† (5-View TTA) ---
    print(">>> æ­£åœ¨å¤„ç†æµ‹è¯•é›† (å¯ç”¨ TTA å¢å¼º)...")
    test_files = sorted(os.listdir(TEST_DIR))
    predictions = []

    # TTA å˜æ¢å‡½æ•°
    def augment(img, mode):
        if mode == 0: return img
        if mode == 1: return cv2.flip(img, 1) # æ°´å¹³ç¿»è½¬
        if mode == 2: return cv2.flip(img, 0) # å‚ç›´ç¿»è½¬
        if mode == 3: return cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)
        if mode == 4: return cv2.rotate(img, cv2.ROTATE_180)
        return img

    for idx, file in enumerate(test_files):
        path = os.path.join(TEST_DIR, file)
        img_orig = cv2.imread(path)
        if img_orig is None: continue
        
        # 5æ¬¡å˜æ¢ï¼Œç´¯åŠ æ¦‚ç‡
        probs_sum = None
        for mode in range(5):
            img_aug = augment(img_orig, mode)
            feat = extract_features(img_aug, kmeans)
            feat_scaled = scaler.transform(feat.reshape(1, -1))
            prob = eclf.predict_proba(feat_scaled)
            
            if probs_sum is None: probs_sum = prob
            else: probs_sum += prob
            
        # å–æœ€å¤§æ¦‚ç‡å¯¹åº”çš„ç±»åˆ«
        pred_idx = np.argmax(probs_sum)
        pred_label = le.inverse_transform([pred_idx])[0]
        
        predictions.append({'file': file, 'species': pred_label})
        if idx % 50 == 0: print(f"é¢„æµ‹è¿›åº¦: {idx}/{len(test_files)}", end='\r')

    # --- Step 6: ä¿å­˜ ---
    df_sub = pd.DataFrame(predictions)
    df_sub.to_csv('submission_final.csv', index=False)
    print("\nğŸ‰ æäº¤æ–‡ä»¶ç”ŸæˆæˆåŠŸ: submission_final.csv")

if __name__ == '__main__':
    main()